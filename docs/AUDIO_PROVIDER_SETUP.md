# Audio Provider Setup Guide

Complete guide for setting up and switching between OpenVoice (free) and ElevenLabs (premium) audio providers in Alkemy AI Studio.

## ğŸ¯ Quick Start

Alkemy supports **provider-agnostic audio processing** - you can start with OpenVoice (free) and upgrade to ElevenLabs later with **zero code changes**.

## ğŸ“‹ Table of Contents

- [Architecture Overview](#architecture-overview)
- [Provider Comparison](#provider-comparison)
- [OpenVoice Setup (Free)](#openvoice-setup-free)
- [ElevenLabs Setup (Premium)](#elevenlabs-setup-premium)
- [Switching Providers](#switching-providers)
- [Usage Examples](#usage-examples)
- [Troubleshooting](#troubleshooting)

---

## Architecture Overview

The audio system uses a **provider abstraction layer** that makes switching between providers as simple as changing one environment variable:

```typescript
// All providers implement the same interface
interface AudioProvider {
  cloneVoice(request): Promise<VoiceCloneResponse>
  generateSpeech(request): Promise<SpeechGenerationResponse>
  editAudio(request): Promise<AudioEditResponse>
  getVoices(): Promise<Voice[]>
}
```

### Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Alkemy AI Studio Frontend           â”‚
â”‚  (Character Identity, Post Production UI)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚   audioService.ts      â”‚  â† Single unified API
       â”‚  (Provider Manager)    â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚                         â”‚
â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OpenVoice  â”‚         â”‚  ElevenLabs    â”‚
â”‚ Provider   â”‚         â”‚  Provider      â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                        â”‚
â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OpenVoice  â”‚         â”‚  ElevenLabs    â”‚
â”‚ Backend    â”‚         â”‚  Cloud API     â”‚
â”‚ (CPU)      â”‚         â”‚  (Hosted)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Provider Comparison

| Feature | OpenVoice (Free) | ElevenLabs (Premium) |
|---------|------------------|----------------------|
| **Cost** | $0 | $99-499/month |
| **Quality** | â­â­â­â­ (90%) | â­â­â­â­â­ (98%) |
| **GPU Required** | âŒ No (CPU only) | âŒ No (Cloud API) |
| **Voice Cloning** | âœ… Yes (6+ sec) | âœ… Yes (1-5 sec) |
| **Emotion Control** | âœ… 15-20 emotions | âœ… 7+ emotions |
| **Paralinguistics** | âœ… Breathing, laughter | âŒ Limited |
| **Processing Time** | 3-8 seconds | 1-2 seconds |
| **Languages** | 6+ languages | 29+ languages |
| **Self-Hosted** | âœ… Yes | âŒ Cloud only |
| **Data Privacy** | âœ… Full control | âš ï¸ Third-party |
| **Setup Complexity** | Medium | Easy |

### Recommendation

- **Start with OpenVoice** for development and testing
- **Upgrade to ElevenLabs** when you need:
  - Higher audio fidelity for AAA productions
  - Faster processing times
  - More language support
  - Managed infrastructure

---

## OpenVoice Setup (Free)

### 1. Backend Setup

OpenVoice requires a Python backend service running on your local machine or server.

#### Install Dependencies

```bash
# Clone OpenVoice repository
git clone https://github.com/myshell-ai/OpenVoice.git
cd OpenVoice

# Install OpenVoice
pip install -e .[all]
pip install git+https://github.com/myshell-ai/MeloTTS.git

# Install FastAPI for API server
pip install fastapi uvicorn python-multipart
```

#### Create API Server

Create `server.py` in the OpenVoice directory:

```python
from fastapi import FastAPI, File, UploadFile, Form
from fastapi.middleware.cors import CORSMiddleware
from openvoice import se_extractor
from openvoice.api import ToneColorConverter
import os

app = FastAPI()

# Enable CORS for Alkemy frontend
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],  # Your Alkemy dev server
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Initialize OpenVoice
converter = ToneColorConverter(config_path="config.json", device='cpu')

@app.get("/health")
async def health_check():
    return {"status": "healthy"}

@app.post("/api/clone-voice")
async def clone_voice(
    reference_audio: UploadFile = File(...),
    voice_name: str = Form(...),
    description: str = Form(None),
    language: str = Form("en")
):
    # Save uploaded audio
    audio_path = f"/tmp/{reference_audio.filename}"
    with open(audio_path, "wb") as f:
        f.write(await reference_audio.read())

    # Extract voice embedding
    target_se, _ = se_extractor.get_se(audio_path, tone_color_embedding_path="/tmp/embeddings")

    # Generate voice ID
    voice_id = f"voice_{hash(voice_name)}"

    # Save embedding
    os.makedirs(f"/tmp/voices/{voice_id}", exist_ok=True)
    # ... save embedding logic

    return {
        "voice_id": voice_id,
        "sample_audio": None,  # Optional: generate sample
        "quality": 85,
        "confidence": 90,
        "processing_time": 0
    }

@app.post("/api/generate-speech")
async def generate_speech(
    text: str = Form(...),
    voice_id: str = Form("default"),
    emotion: str = Form("neutral"),
    speed: float = Form(1.0),
    language: str = Form("en")
):
    # Load voice embedding
    # ... load embedding logic

    # Generate speech with OpenVoice
    # ... generation logic

    return {
        "audio_url": "data:audio/mp3;base64,...",  # Base64 audio
        "duration": 0,
        "sample_rate": 22050,
        "processing_time": 0
    }

@app.post("/api/edit-audio")
async def edit_audio(
    input_audio: UploadFile = File(...),
    edit_type: str = Form(...),
    edit_params: str = Form(...)  # JSON string
):
    # Edit audio logic
    return {
        "audio_url": "data:audio/mp3;base64,...",
        "original_duration": 0,
        "new_duration": 0,
        "processing_time": 0
    }

@app.get("/api/voices")
async def get_voices():
    # Return list of available voices
    return []

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

#### Run the Server

```bash
python server.py
```

The OpenVoice API will be available at `http://localhost:8000`.

### 2. Frontend Configuration

Set environment variables in `.env.local`:

```bash
# OpenVoice Configuration
VITE_AUDIO_PROVIDER=openvoice
VITE_OPENVOICE_API_URL=http://localhost:8000
```

### 3. Verify Setup

Test the connection:

```typescript
import { audioService } from './services/audioService';

const isAvailable = await audioService.isAvailable();
console.log('OpenVoice available:', isAvailable);  // Should be true
```

---

## ElevenLabs Setup (Premium)

### 1. Get API Key

1. Sign up at [elevenlabs.io](https://elevenlabs.io)
2. Choose a plan ($99-499/month)
3. Get your API key from the dashboard

### 2. Frontend Configuration

Set environment variables in `.env.local`:

```bash
# ElevenLabs Configuration
VITE_AUDIO_PROVIDER=elevenlabs
VITE_ELEVENLABS_API_KEY=your_api_key_here
```

### 3. Verify Setup

Test the connection:

```typescript
import { audioService } from './services/audioService';

const isAvailable = await audioService.isAvailable();
console.log('ElevenLabs available:', isAvailable);  // Should be true
```

**That's it!** No backend server needed - ElevenLabs is cloud-hosted.

---

## Switching Providers

### Method 1: Environment Variable (Recommended)

Simply change one line in `.env.local`:

```bash
# Switch from OpenVoice to ElevenLabs
VITE_AUDIO_PROVIDER=elevenlabs

# Switch back to OpenVoice
VITE_AUDIO_PROVIDER=openvoice
```

Restart your dev server and you're done!

### Method 2: Runtime Switching

Switch providers programmatically:

```typescript
import { audioService } from './services/audioService';
import { AudioProviderType } from './types/audioProvider';

// Switch to ElevenLabs
await audioService.switchProvider(AudioProviderType.ELEVENLABS, {
  provider: AudioProviderType.ELEVENLABS,
  apiKey: 'your_api_key'
});

// Switch to OpenVoice
await audioService.switchProvider(AudioProviderType.OPENVOICE, {
  provider: AudioProviderType.OPENVOICE,
  baseUrl: 'http://localhost:8000'
});
```

### Method 3: User Settings UI

Allow users to switch providers in the UI:

```typescript
// In your Settings component
<select onChange={(e) => handleProviderSwitch(e.target.value)}>
  <option value="openvoice">OpenVoice (Free)</option>
  <option value="elevenlabs">ElevenLabs (Premium)</option>
</select>

async function handleProviderSwitch(provider: string) {
  await audioService.switchProvider(provider as AudioProviderType);
  // Provider change is automatically saved to Supabase
}
```

---

## Usage Examples

All examples work **identically** regardless of which provider is active!

### Clone a Character Voice

```typescript
import { audioService } from './services/audioService';

// Upload voice sample (6+ seconds)
const referenceAudio = new File([audioBlob], 'voice_sample.mp3');

// Clone voice
const characterVoice = await audioService.cloneCharacterVoice(
  'character-123',
  'John Smith',
  referenceAudio,
  'Lead character voice with British accent'
);

// Result includes voiceId that works with either provider
console.log('Voice cloned:', characterVoice.voiceId);
```

### Generate Dialogue with Emotion

```typescript
// Generate dialogue (works with OpenVoice or ElevenLabs)
const dialogue = await audioService.generateCharacterDialogue(
  characterVoice,
  "I can't believe you did that!",
  'angry',  // Emotion
  'Scene 5: Confrontation in the rain'  // Context
);

// Audio is automatically uploaded to Supabase
console.log('Dialogue generated:', dialogue.outputAudio);
```

### Edit Dialogue Emotion

```typescript
// Edit existing dialogue emotion
const editedAudio = await audioService.editDialogueEmotion(
  originalAudioUrl,
  'sad',  // New emotion
  "I can't believe you did that!",
  characterVoice
);

console.log('Edited dialogue:', editedAudio.audioUrl);
```

### Get Available Voices

```typescript
// Get all available voices (built-in + cloned)
const voices = await audioService.getVoices();

voices.forEach(voice => {
  console.log(`${voice.name} (${voice.language})`);
  console.log(`  Quality: ${voice.metadata?.quality}%`);
  console.log(`  Custom: ${voice.isCustom}`);
});
```

---

## Troubleshooting

### OpenVoice Issues

**Problem:** Connection refused to localhost:8000

**Solution:**
```bash
# Check if server is running
curl http://localhost:8000/health

# Start server if not running
cd OpenVoice && python server.py
```

**Problem:** Low audio quality

**Solution:**
- Use 6+ second reference audio
- Ensure audio is at least 16kHz sample rate
- Try higher quality reference recordings

### ElevenLabs Issues

**Problem:** 401 Unauthorized

**Solution:**
```bash
# Verify API key in .env.local
VITE_ELEVENLABS_API_KEY=your_actual_key_here

# Test API key with curl
curl -H "xi-api-key: your_key" https://api.elevenlabs.io/v1/user
```

**Problem:** Rate limit exceeded

**Solution:**
- Upgrade to higher tier plan
- Implement request queuing
- Add retry logic with exponential backoff

### General Issues

**Problem:** Provider not switching

**Solution:**
```typescript
// Check active provider
const config = audioService.getConfiguration();
console.log('Active provider:', config.active);

// Force reload configuration
await audioService.loadConfiguration();
```

**Problem:** Voice cloning fails

**Solution:**
1. Check audio file size (< 10MB)
2. Verify audio duration (6+ seconds)
3. Check supported formats (mp3, wav, ogg)
4. Review console logs for specific error

---

## Production Deployment

### OpenVoice Production

Deploy OpenVoice backend to a cloud instance:

```bash
# Docker deployment
docker build -t openvoice-server .
docker run -p 8000:8000 openvoice-server

# Or use cloud providers
# - AWS EC2 (t3.medium or larger)
# - Google Cloud Compute Engine
# - DigitalOcean Droplets
```

Update production environment variables:

```bash
VITE_OPENVOICE_API_URL=https://your-openvoice-server.com
```

### ElevenLabs Production

No backend deployment needed! Just set the API key:

```bash
VITE_ELEVENLABS_API_KEY=your_production_api_key
```

---

## Cost Comparison

### Monthly Costs

| Scenario | OpenVoice | ElevenLabs |
|----------|-----------|------------|
| Development | $0 (local) | $0 (trial) |
| Small team (< 100K chars/mo) | $10-20 (hosting) | $99/month |
| Medium team (< 1M chars/mo) | $20-50 (hosting) | $330/month |
| Large team (> 1M chars/mo) | $50-100 (hosting) | $499/month |

### Cost Optimization

- Start with OpenVoice for prototyping
- Use ElevenLabs for final production audio
- Cache generated audio in Supabase
- Implement request deduplication

---

## Next Steps

1. âœ… Choose your provider (OpenVoice or ElevenLabs)
2. âœ… Complete setup following this guide
3. âœ… Test voice cloning with a sample character
4. âœ… Integrate with Character Identity system
5. âœ… Add emotion editing to Post Production tab
6. âœ… Deploy to production

**Questions?** Check the [main documentation](/docs/CLAUDE.md) or open an issue.

---

**Last Updated:** 2025-11-17
**Author:** Qualia Solutions
**Version:** V2.0 Alpha